# Implementation Plan - React RL Platform

## Goal
Develop a web platform to visualize and run RL agents (DP, TD, Policy Gradient) on MsPacman, KungFuMaster, and MiniWorld Maze.

## User Review Required
> [!IMPORTANT]
> **Algorithm Compatibility**: Dynamic Programming (Policy/Value Iteration) requires a known model and small discrete state space. It is **incompatible** with raw Atari/MiniWorld environments.
> **Proposed Solution**: 
> 1. Restrict DP methods to a simplified "GridWorld" version of the Maze or disable them for Atari in the UI.
> 2. Implement Deep RL (DQN, Actor-Critic) for Atari/MiniWorld to satisfy "Advanced RL" requirements.
> 3. Tabular Q-Learning/SARSA will be implemented for discrete logic, but DQN is needed for the visual games.

## Logic/Architecture

### Tech Stack
- **Frontend**: React (Vite), TailwindCSS, Recharts.
- **Backend**: Python (FastAPI), Uvicorn.
- **RL Library**: PyTorch (for Deep RL), NumPy (for Tabular/Env wrappers).
- **Communication**: WebSockets (State streaming).

### Component Structure
1. **Frontend** (`frontend/`)
    - `App.tsx`: Main router.
    - `LandingPage`: Game selection cards.
    - `ConfigPage`: Algorithm selection & Hyperparams.
    - `Dashboard`: 
        - `GameCanvas`: Renders base64 frames.
        - `StatsPanel`: Live line charts (Reward/Episode).
        - `Controls`: Start/Stop/Reset.

2. **Backend** (`backend/`)
    - `main.py`: FastAPI app, WS routes.
    - `envs/`: Gymnasium wrappers (Resize, Grayscale, PyTorch-ready).
    - `agents/`:
        - `base.py`: Abstract Interface.
        - `dp.py`: Value/Policy Iteration (GridWorld logic).
        - `td.py`: Q-Learning (Tabular & Deep), SARSA.
        - `pg.py`: REINFORCE, Actor-Critic.
    - `training.py`: Loop handling `env.step()`, `agent.act()`, and WS broadcast.

## Proposed Changes

### Backend Setup
#### [NEW] [fastapi_app](file:///c:/Users/Pc/AdvML/backend/main.py)
- FastAPI entry point.
- WebSocket endpoint `/ws/run/{game_id}/{algo_id}`.

#### [NEW] [rl_agents](file:///c:/Users/Pc/AdvML/backend/agents.py)
- Implementation of `DQNAgent`, `ActorCriticAgent`, `TabularAgent`.
- PyTorch models for visual inputs (CNN).

#### [NEW] [environments](file:///c:/Users/Pc/AdvML/backend/envs.py)
- `make_env(game_id)` factory.
- Wrappers: `ImageToPyTorch`, `FrameStack`.

### Frontend Setup
#### [NEW] [frontend_setup](file:///c:/Users/Pc/AdvML/frontend/package.json)
- React dependencies, Recharts, Tailwind.

#### [NEW] [components](file:///c:/Users/Pc/AdvML/frontend/src/components/)
- `GameCard.tsx`, `Dashboard.tsx`, `Charts.tsx`.

## Verification Plan

### Automated Tests
- Python unit tests for Agent forward passes (`pytest`).
- Check if `gymnasium` envs load correctly.

### Manual Verification
- Run FastAPI server.
- Connect Frontend.
- Select "MsPacman" -> "DQN".
- Verify game renders and graph updates.
